{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ee00d1c-8057-41ed-98cd-cd64c58be1e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "all_data = []\n",
    "page = 2\n",
    "\n",
    "while True:\n",
    "    url = f\"https://reqres.in/api/users?page={page}\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        break\n",
    "    \n",
    "    result = response.json()\n",
    "    \n",
    "    data = result.get(\"data\", [])\n",
    "    \n",
    "    if not data:\n",
    "        break  # stop if no data returned\n",
    "    \n",
    "    all_data.extend(data)\n",
    "    page += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9da62ee9-b751-4309-baf2-560c2c46d8b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# all_data already contains only user data; other keys are skipped\n",
    "print(all_data[0])  # sample record\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62d6c167-b7cf-4aff-af0e-1b115ae0a81e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "from pyspark.sql import Row\n",
    "\n",
    "# Define schema\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"email\", StringType(), True),\n",
    "    StructField(\"first_name\", StringType(), True),\n",
    "    StructField(\"last_name\", StringType(), True),\n",
    "    StructField(\"avatar\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Convert to list of Rows\n",
    "rows = [Row(**item) for item in all_data]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(rows, schema=schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e37c3f99-80ce-456a-b7dd-862dcbe7833b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, current_date\n",
    "\n",
    "df = df.withColumn(\"site_address\", lit(\"reqres.in\")) \\\n",
    "       .withColumn(\"load_date\", current_date())\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "918985ad-96d2-4e91-a10e-cbf587bbce67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.write \\\n",
    "  .format(\"delta\") \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .option(\"overwriteSchema\", \"true\") \\\n",
    "  .save(\"/Volumes/workspace/default/databricks_assignment/site_info/person_info\")\n",
    "\n",
    "df2 = spark.read.format(\"delta\").load(\"/Volumes/workspace/default/databricks_assignment/site_info/person_info\")\n",
    "display(df2)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "fetch_api_data_to_delta",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
